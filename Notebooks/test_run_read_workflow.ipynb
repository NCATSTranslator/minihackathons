{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook was only created to test the ReadAndRunAllWorkFlows.py\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pull the ara results and look through KF+G edge graphs and pull the povenance attribute and make a table that will look like\n",
    "#rows will be kp\n",
    "#col be workflows\n",
    "#entry would be the ara's that had edges in kp in the workflow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#https://ars.ci.transltr.io/ars/api --- \n",
    "#https://arax.ci.transltr.io -- backup url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def submit_to_ars(m,ars_url='https://ars.transltr.io/ars/api',arax_url='https://arax.ncats.io'):\n",
    "    submit_url=f'{ars_url}/submit'\n",
    "    response = requests.post(submit_url,json=m)\n",
    "    try:\n",
    "        message_id = response.json()['pk']\n",
    "    except:\n",
    "        print('fail')\n",
    "        message_id = None\n",
    "    print(f'{arax_url}/?source=ARS&id={message_id}')\n",
    "    return message_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def retrieve_ars_results(mid,ars_url='https://ars.transltr.io/ars/api'):\n",
    "    pk = 'https://arax.ncats.io/?source=ARS&id=' + mid\n",
    "    message_url = f'{ars_url}/messages/{mid}?trace=y'\n",
    "    response = requests.get(message_url)\n",
    "    j = response.json()\n",
    "    print( j['status'] )\n",
    "    results = {}\n",
    "    dictionary = {}\n",
    "    dictionary_2 = {}\n",
    "    for child in j['children']:\n",
    "        print(child['status'])\n",
    "        if child['status']  == 'Done':\n",
    "            childmessage_id = child['message']\n",
    "            child_url = f'{ars_url}/messages/{childmessage_id}'\n",
    "            try:\n",
    "                child_response = requests.get(child_url).json()\n",
    "                nresults = len(child_response['fields']['data']['message']['results'])\n",
    "                if nresults > 0:\n",
    "                    results[child['actor']['agent']] = {'message':child_response['fields']['data']['message']}\n",
    "            except Exception as e:\n",
    "                nresults=0\n",
    "                child['status'] = 'ARS Error'\n",
    "        elif child['status'] == 'Error':\n",
    "            nresults=0\n",
    "            childmessage_id = child['message']\n",
    "            child_url = f'{ars_url}/messages/{childmessage_id}'\n",
    "            try:\n",
    "                child_response = requests.get(child_url).json()\n",
    "                results[child['actor']['agent']] = {'message':child_response['fields']['data']['message']}\n",
    "            except Exception as e:\n",
    "                #print(e)\n",
    "                child['status'] = 'ARS Error'\n",
    "        else:\n",
    "            nresults = 0\n",
    "            \n",
    "        dictionary['pk_id'] =  pk  \n",
    "            \n",
    "        if ((child['status'] == 'Done') & (nresults == 0)):\n",
    "            dictionary[child['actor']['agent']] = 'No Results'\n",
    "            #test =  [child['actor']['agent'], 'No Results']\n",
    "        elif ((child['status'] == 'ARS Error') & (nresults == 0)):\n",
    "            dictionary[child['actor']['agent']] = 'ARS Error'\n",
    "        elif ((child['status'] == 'Error') & (nresults == 0)):\n",
    "            dictionary[child['actor']['agent']] = 'Error'\n",
    "            #test =  [child['actor']['agent'], 'ARS Error']\n",
    "        elif ((child['status'] == 'Done') & (nresults != 0)):\n",
    "            #test =  [child['actor']['agent'], 'Results']\n",
    "            dictionary[child['actor']['agent']] = 'Results' \n",
    "        \n",
    "        \n",
    "        print(child['actor']['agent'], child['status'], nresults)\n",
    "        #test =  [child['actor']['agent'], child['status'], nresults]\n",
    "        #test2.append(test)\n",
    "    return dictionary\n",
    "\n",
    "\n",
    "#def submit_to_devars(m):\n",
    "#    return submit_to_ars(m,ars_url='https://ars-dev.transltr.io/ars/api',arax_url='https://arax.ncats.io')\n",
    "\n",
    "#def retrieve_devars_results(m):\n",
    "#     return retrieve_ars_results(m,ars_url='https://ars-dev.transltr.io/ars/api')\n",
    "\n",
    "def printjson(j):\n",
    "    print(json.dumps(j,indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Submiting more than one jobs (test)\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "urls = ['/Users/priyash/Documents/GitHub/minihackathons/2021-12_demo/workflowA/A.9_EGFR_advanced.json', '/Users/priyash/Documents/GitHub/minihackathons/2021-12_demo/workflowA/A.1_RHOBTB2.json']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dict_workflows = {}\n",
    "for i in urls:\n",
    "    feature = (os.path.splitext(os.path.basename(i))[0])\n",
    "    print(i, feature)\n",
    "    with open(i,'r') as inf:\n",
    "        query = json.load(inf)\n",
    "        kcresult = submit_to_ars(query)\n",
    "        #xx = retrieve_devars_results(kcresult)\n",
    "        \n",
    "        dict_workflows[feature] = kcresult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dict_workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "workflow_result_messages = {}\n",
    "for keys, val in dict_workflows.items():\n",
    "    print(keys, val)\n",
    "    \n",
    "    result_status = retrieve_ars_results(val)\n",
    "    \n",
    "    workflow_result_messages[keys] = result_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "workflow_result_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "col = []\n",
    "final_dict = defaultdict(list)\n",
    "for k in sorted(workflow_result_messages):\n",
    "    print(k)\n",
    "    col.append(k)\n",
    "    \n",
    "    for key, value in workflow_result_messages[k].items():\n",
    "        if key.startswith('kp-'):\n",
    "            key_mod = key.replace('kp-','')\n",
    "        else:\n",
    "            key_mod = key\n",
    "        \n",
    "        final_dict[key_mod].append(value)\n",
    "\n",
    "    final_dict = dict(final_dict)\n",
    "    \n",
    "df = pd.DataFrame(final_dict).T\n",
    "df.rename(columns=dict(zip(df.columns, col)), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.loc['pk_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.to_excel('test_ara_worklow.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Test for individual run\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('/Users/priyash/Documents/GitHub/minihackathons/2021-12_demo/workflowA/A.0_RHOBTB2_direct.json') as inf:\n",
    "    query1 = json.load(inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "printjson(query1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kcresult = submit_to_ars(query1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#retrieve_ars_results(kcresult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "kcresult = 'b3a39c22-e315-4e89-a642-1501d13461c2'\n",
    "ars_url='https://ars.transltr.io/ars/api'\n",
    "pk = 'https://arax.ncats.io/?source=ARS&id=' + kcresult\n",
    "message_url = f'{ars_url}/messages/{kcresult}?trace=y'\n",
    "response = requests.get(message_url)\n",
    "j = response.json()\n",
    "\n",
    "def flatten_list(_2d_list):\n",
    "    flat_list = []\n",
    "    # Iterate through the outer list\n",
    "    for element in _2d_list:\n",
    "        if type(element) is list:\n",
    "            # If the element is of type list, iterate through the sublist\n",
    "            for item in element:\n",
    "                flat_list.append(item)\n",
    "        else:\n",
    "            flat_list.append(element)\n",
    "    return flat_list\n",
    "\n",
    "check_sheet = pd.read_csv(\"/Users/priyash/Documents/GitHub/minihackathons/Notebooks/Query results to include or exclude - Sheet1.csv\", header=0)\n",
    "\n",
    "#check_sheet.set_index('Workflow', inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Workflow</th>\n",
       "      <th>Curie</th>\n",
       "      <th>N (size of list of results)</th>\n",
       "      <th>Query node ID</th>\n",
       "      <th>Include/Exclude</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A.0_RHOBTB2_direct.json</td>\n",
       "      <td>PUBCHEM.COMPOUND:2950270</td>\n",
       "      <td>10.0</td>\n",
       "      <td>n1</td>\n",
       "      <td>Include</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Note: this example row means that for workflow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B.1_DILI-three-hop-interacts-with.json</td>\n",
       "      <td>CHEBI:41879</td>\n",
       "      <td>500.0</td>\n",
       "      <td>n3</td>\n",
       "      <td>Include</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Equivalent identifiers are equally acceptable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B.1_DILI-three-hop-interacts-with.json</td>\n",
       "      <td>MESH:D000077185</td>\n",
       "      <td>500.0</td>\n",
       "      <td>n3</td>\n",
       "      <td>Include</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Equivalent identifiers are equally acceptable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B.1_DILI-three-hop-interacts-with.json</td>\n",
       "      <td>MESH:D000077385</td>\n",
       "      <td>500.0</td>\n",
       "      <td>n3</td>\n",
       "      <td>Include</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Equivalent identifiers are equally acceptable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B.1_DILI-three-hop-interacts-with.json</td>\n",
       "      <td>MESH:D003474</td>\n",
       "      <td>500.0</td>\n",
       "      <td>n3</td>\n",
       "      <td>Include</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Equivalent identifiers are equally acceptable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B.1_DILI-three-hop-interacts-with.json</td>\n",
       "      <td>RXNORM:40068</td>\n",
       "      <td>500.0</td>\n",
       "      <td>n3</td>\n",
       "      <td>Include</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Equivalent identifiers are equally acceptable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B.1_DILI-three-hop-interacts-with.json</td>\n",
       "      <td>PUBCHEM.COMPOUND:5877</td>\n",
       "      <td>500.0</td>\n",
       "      <td>n3</td>\n",
       "      <td>Include</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Equivalent identifiers are equally acceptable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>B.1_DILI-three-hop-interacts-with.json</td>\n",
       "      <td>PUBCHEM.COMPOUND:5755</td>\n",
       "      <td>500.0</td>\n",
       "      <td>n3</td>\n",
       "      <td>Include</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Equivalent identifiers are equally acceptable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>D.1_parkinsons-crohns.json</td>\n",
       "      <td>NCBIGene:120892</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n01</td>\n",
       "      <td>include</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LRRK2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>D.1_parkinsons-crohns.json</td>\n",
       "      <td>NCBIGene:11315</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n01</td>\n",
       "      <td>include</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PARK7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>D.1_parkinsons-crohns.json</td>\n",
       "      <td>NCBIGene:110357</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n01</td>\n",
       "      <td>include</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MOD2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>D.2_ssri-heart-disease.json</td>\n",
       "      <td>NCBIGene:3988</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n01</td>\n",
       "      <td>include</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LIPA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>D.2_ssri-heart-disease.json</td>\n",
       "      <td>NCBIGene:5627</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n01</td>\n",
       "      <td>include</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PROS1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>D.2_ssri-heart-disease.json</td>\n",
       "      <td>NCBIGene:7043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n01</td>\n",
       "      <td>include</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TGFB3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>D.3_ssri-heart-disease-one-hop.json</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>e00</td>\n",
       "      <td>include</td>\n",
       "      <td>NaN</td>\n",
       "      <td>any clinical edge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>D.4_tryptophan-kyurenine.json</td>\n",
       "      <td>REACT:R-HSA-888614</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n02</td>\n",
       "      <td>include</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IDO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>D.4_tryptophan-kyurenine.json</td>\n",
       "      <td>KEGG:1.13.11.52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n02</td>\n",
       "      <td>include</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IDO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>D.4_tryptophan-kyurenine.json</td>\n",
       "      <td>REACT:R-HSA-888614</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n03</td>\n",
       "      <td>include</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IDO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>D.4_tryptophan-kyurenine.json</td>\n",
       "      <td>KEGG:1.13.11.52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n03</td>\n",
       "      <td>include</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IDO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>D.6_metformin-ferritin.json</td>\n",
       "      <td>UniProtKB:P54646</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n01</td>\n",
       "      <td>include</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AAPK protein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>D.6_metformin-ferritin.json</td>\n",
       "      <td>NCBIGene:5563</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n01</td>\n",
       "      <td>include</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AMPK gene</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>D.6_metformin-ferritin.json</td>\n",
       "      <td>UniProtKB:P42345</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n02</td>\n",
       "      <td>include</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MTOR protein</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Workflow                     Curie  \\\n",
       "0                  A.0_RHOBTB2_direct.json  PUBCHEM.COMPOUND:2950270   \n",
       "1   B.1_DILI-three-hop-interacts-with.json               CHEBI:41879   \n",
       "2   B.1_DILI-three-hop-interacts-with.json           MESH:D000077185   \n",
       "3   B.1_DILI-three-hop-interacts-with.json           MESH:D000077385   \n",
       "4   B.1_DILI-three-hop-interacts-with.json              MESH:D003474   \n",
       "5   B.1_DILI-three-hop-interacts-with.json              RXNORM:40068   \n",
       "6   B.1_DILI-three-hop-interacts-with.json     PUBCHEM.COMPOUND:5877   \n",
       "7   B.1_DILI-three-hop-interacts-with.json     PUBCHEM.COMPOUND:5755   \n",
       "8               D.1_parkinsons-crohns.json           NCBIGene:120892   \n",
       "9               D.1_parkinsons-crohns.json            NCBIGene:11315   \n",
       "10              D.1_parkinsons-crohns.json           NCBIGene:110357   \n",
       "11             D.2_ssri-heart-disease.json             NCBIGene:3988   \n",
       "12             D.2_ssri-heart-disease.json             NCBIGene:5627   \n",
       "13             D.2_ssri-heart-disease.json             NCBIGene:7043   \n",
       "14     D.3_ssri-heart-disease-one-hop.json                       NaN   \n",
       "15           D.4_tryptophan-kyurenine.json        REACT:R-HSA-888614   \n",
       "16           D.4_tryptophan-kyurenine.json           KEGG:1.13.11.52   \n",
       "17           D.4_tryptophan-kyurenine.json        REACT:R-HSA-888614   \n",
       "18           D.4_tryptophan-kyurenine.json           KEGG:1.13.11.52   \n",
       "19             D.6_metformin-ferritin.json          UniProtKB:P54646   \n",
       "20             D.6_metformin-ferritin.json             NCBIGene:5563   \n",
       "21             D.6_metformin-ferritin.json          UniProtKB:P42345   \n",
       "\n",
       "    N (size of list of results) Query node ID Include/Exclude  Unnamed: 5  \\\n",
       "0                          10.0            n1         Include         NaN   \n",
       "1                         500.0            n3         Include         NaN   \n",
       "2                         500.0            n3         Include         NaN   \n",
       "3                         500.0            n3         Include         NaN   \n",
       "4                         500.0            n3         Include         NaN   \n",
       "5                         500.0            n3         Include         NaN   \n",
       "6                         500.0            n3         Include         NaN   \n",
       "7                         500.0            n3         Include         NaN   \n",
       "8                           NaN           n01         include         NaN   \n",
       "9                           NaN           n01         include         NaN   \n",
       "10                          NaN           n01         include         NaN   \n",
       "11                          NaN           n01         include         NaN   \n",
       "12                          NaN           n01         include         NaN   \n",
       "13                          NaN           n01         include         NaN   \n",
       "14                          NaN           e00         include         NaN   \n",
       "15                          NaN           n02         include         NaN   \n",
       "16                          NaN           n02         include         NaN   \n",
       "17                          NaN           n03         include         NaN   \n",
       "18                          NaN           n03         include         NaN   \n",
       "19                          NaN           n01         include         NaN   \n",
       "20                          NaN           n01         include         NaN   \n",
       "21                          NaN           n02         include         NaN   \n",
       "\n",
       "                                           Unnamed: 6  \n",
       "0   Note: this example row means that for workflow...  \n",
       "1       Equivalent identifiers are equally acceptable  \n",
       "2       Equivalent identifiers are equally acceptable  \n",
       "3       Equivalent identifiers are equally acceptable  \n",
       "4       Equivalent identifiers are equally acceptable  \n",
       "5       Equivalent identifiers are equally acceptable  \n",
       "6       Equivalent identifiers are equally acceptable  \n",
       "7       Equivalent identifiers are equally acceptable  \n",
       "8                                               LRRK2  \n",
       "9                                               PARK7  \n",
       "10                                               MOD2  \n",
       "11                                               LIPA  \n",
       "12                                              PROS1  \n",
       "13                                              TGFB3  \n",
       "14                                  any clinical edge  \n",
       "15                                                IDO  \n",
       "16                                                IDO  \n",
       "17                                                IDO  \n",
       "18                                                IDO  \n",
       "19                                       AAPK protein  \n",
       "20                                          AMPK gene  \n",
       "21                                       MTOR protein  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'D.1_parkinsons-crohns.json' in list(check_sheet.Workflow):\n",
    "    print('True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 NCBIGene:120892\n",
      "0 NCBIGene:120892 n01 2000\n",
      "1 NCBIGene:11315\n",
      "1 NCBIGene:11315 n01 2000\n",
      "2 NCBIGene:110357\n",
      "2 NCBIGene:110357 n01 2000\n"
     ]
    }
   ],
   "source": [
    "if 'D.1_parkinsons-crohns.json' in list(check_sheet.Workflow):\n",
    "    dfy = check_sheet[check_sheet['Workflow']== 'D.1_parkinsons-crohns.json']\n",
    "dfy.reset_index(drop=True)\n",
    "\n",
    "for index,val in enumerate(dfy.Curie):\n",
    "    print(index,val)\n",
    "    node_num = dfy.iloc[index][3]\n",
    "    query_id = val\n",
    "    if np.isnan(dfy.iloc[index][2]) == True:\n",
    "        len_check = 2000\n",
    "    else:\n",
    "        len_check = dfy.iloc[index][2]\n",
    "\n",
    "    print(index, query_id, node_num, len_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if np.isnan(dfy.iloc[0][2]) == True:\n",
    "    print('walla')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_sheet.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "kp-chp Done 0\n",
      "Done\n",
      "kp-icees-dili ARS Error 0\n",
      "Done\n",
      "kp-openpredict Done 0\n",
      "Done\n",
      "kp-cam Done 0\n",
      "Done\n",
      "ara-explanatory Done 0\n",
      "Error\n",
      "ara-bte Error 0\n",
      "Error\n",
      "ara-arax Error 0\n",
      "Error\n",
      "ara-unsecret Error 0\n",
      "Error\n",
      "ara-aragorn Error 0\n",
      "Error\n",
      "ara-robokop Error 0\n",
      "Unknown\n",
      "kp-genetics Unknown 0\n",
      "Error\n",
      "kp-molecular Error 0\n",
      "Done\n",
      "0 NCBIGene:120892\n",
      "curie id: NCBIGene:120892 : INCLUDED at postion N == [0] on n01\n",
      "1 NCBIGene:11315\n",
      "curie id: NCBIGene:11315 : INCLUDED at postion N == [2] on n01\n",
      "2 NCBIGene:110357\n",
      "False\n",
      "ara-improving Done 22\n",
      "Done\n",
      "kp-icees ARS Error 0\n",
      "Done\n",
      "kp-textmining Done 0\n",
      "Error\n",
      "ara-aragorn-exp Error 0\n",
      "Unknown\n",
      "ara-ncats Unknown 0\n",
      "Error\n",
      "kp-cohd Error 0\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "dictionary = {}\n",
    "dictionary_2 = {}\n",
    "dict3 = {}\n",
    "for child in j['children']:\n",
    "    print(child['status'])\n",
    "    error_code = child['code']\n",
    "\n",
    "    if child['status']  == 'Done':\n",
    "        childmessage_id = child['message']\n",
    "        child_url = f'{ars_url}/messages/{childmessage_id}'\n",
    "        try:\n",
    "            \n",
    "            child_response = requests.get(child_url).json()\n",
    "            nresults = len(child_response['fields']['data']['message']['results'])\n",
    "            \n",
    "            if nresults > 0:\n",
    "                results[child['actor']['agent']] = {'message':child_response['fields']['data']['message']}\n",
    "                \n",
    "            \n",
    "                if 'D.1_parkinsons-crohns.json' in list(check_sheet.Workflow):\n",
    "                    dfy = check_sheet[check_sheet['Workflow']== 'D.1_parkinsons-crohns.json']\n",
    "\n",
    "                dfy.reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "                for index,curie_id in enumerate(dfy.Curie):\n",
    "                    print(index,curie_id)\n",
    "                    node_num = dfy.iloc[index][3]\n",
    "                    query_id = curie_id\n",
    "                    if np.isnan(dfy.iloc[index][2]) == True:\n",
    "                        len_check = len(child_response['fields']['data']['message']['results'])\n",
    "                    else:\n",
    "                        len_check = dfy.iloc[index][2]\n",
    "\n",
    "                    #print(node_num, query_id, len_check)\n",
    "\n",
    "                    locs = []\n",
    "                    for x, val in enumerate(child_response['fields']['data']['message']['results']):\n",
    "                        #print(val)\n",
    "\n",
    "                        if x < len_check:\n",
    "\n",
    "                            if query_id in val['node_bindings'][node_num][0]['id']:\n",
    "                                locs.append(x)\n",
    "                    if not locs:\n",
    "                        check_result = f'False'\n",
    "                        print(check_result)\n",
    "                        #pass\n",
    "                    else:\n",
    "                        check_result = f'True'\n",
    "                        print('curie id:', query_id, ': INCLUDED at postion N ==', locs, 'on', node_num)\n",
    "\n",
    "                    dict3[curie_id] = check_result\n",
    "            #else:\n",
    "                #continue\n",
    "            \n",
    "            if child_response['fields']['data']['message']['knowledge_graph']['edges']:\n",
    "                if child_response['fields']['data']['message']['knowledge_graph']['edges'].keys():\n",
    "                        edge_ex = child_response['fields']['data']['message']['knowledge_graph']['edges']\n",
    "                        test_att_values =[]\n",
    "                        for val in child_response['fields']['data']['message']['knowledge_graph']['edges'].keys():\n",
    "                            #print(val)\n",
    "\n",
    "                            for tx in edge_ex[val]['attributes']:\n",
    "                                if (tx['attribute_type_id'] == 'biolink:primary_knowledge_source') or (tx['attribute_type_id'] == 'biolink:original_knowledge_source') or (tx['attribute_type_id'] == 'biolink:aggregator_knowledge_source') :\n",
    "\n",
    "\n",
    "                                    value_att = tx['value']\n",
    "\n",
    "                                    test_att_values.append(value_att)\n",
    "                                    test_att = set(flatten_list(test_att_values))\n",
    "\n",
    "\n",
    "                                    dictionary_2[child['actor']['agent']] = test_att\n",
    "                #else:\n",
    "                    #dictionary_2[child['actor']['agent']] = [] \n",
    "            #else:\n",
    "               # dictionary_2[child['actor']['agent']] = []\n",
    "\n",
    "        except Exception as e:\n",
    "            nresults=0\n",
    "            child['status'] = 'ARS Error'\n",
    "            #dictionary_2[child['actor']['agent']] = []\n",
    "\n",
    "\n",
    "\n",
    "    elif child['status'] == 'Error':\n",
    "        nresults=0\n",
    "        childmessage_id = child['message']\n",
    "        child_url = f'{ars_url}/messages/{childmessage_id}'\n",
    "        try:\n",
    "            child_response = requests.get(child_url).json()\n",
    "            results[child['actor']['agent']] = {'message':child_response['fields']['data']['message']}\n",
    "            #dictionary_2[child['actor']['agent']] = []\n",
    "        except Exception as e:\n",
    "            #print(e)\n",
    "            child['status'] = 'ARS Error'\n",
    "            #dictionary_2[child['actor']['agent']] = []\n",
    "\n",
    "\n",
    "    else:\n",
    "        nresults = 0\n",
    "        #dictionary_2[child['actor']['agent']] = []\n",
    "\n",
    "    dictionary['pk_id'] =  pk  \n",
    "\n",
    "    if ((child['status'] == 'Done') & (nresults == 0)):\n",
    "        dictionary[child['actor']['agent']] = 'No Results: ' + str(error_code)\n",
    "        #test =  [child['actor']['agent'], 'No Results']\n",
    "    elif ((child['status'] == 'ARS Error') & (nresults == 0)):\n",
    "        dictionary[child['actor']['agent']] = 'ARS Error: ' + str(error_code)\n",
    "    elif ((child['status'] == 'Error') & (nresults == 0)):\n",
    "        dictionary[child['actor']['agent']] = 'Error: ' + str(error_code)\n",
    "        #test =  [child['actor']['agent'], 'ARS Error']\n",
    "    elif ((child['status'] == 'Done') & (nresults != 0)):\n",
    "        #test =  [child['actor']['agent'], 'Results']\n",
    "        dictionary[child['actor']['agent']] = 'Results: ' + str(error_code) + str(dict3)\n",
    "    elif ((child['status'] == 'Unknown') & (nresults == 0)):\n",
    "        #test =  [child['actor']['agent'], 'Results']\n",
    "        dictionary[child['actor']['agent']] = 'Unknown: ' + str(error_code) \n",
    "\n",
    "    print(child['actor']['agent'], child['status'], nresults)\n",
    "    #test =  [child['actor']['agent'], child['status'], nresults]\n",
    "    #test2.append(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dictionary_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pk_id': 'https://arax.ncats.io/?source=ARS&id=b3a39c22-e315-4e89-a642-1501d13461c2',\n",
       " 'kp-chp': 'No Results: 200',\n",
       " 'kp-icees-dili': 'ARS Error: 200',\n",
       " 'kp-openpredict': 'No Results: 200',\n",
       " 'kp-cam': 'No Results: 200',\n",
       " 'ara-explanatory': 'No Results: 200',\n",
       " 'ara-bte': 'Error: 598',\n",
       " 'ara-arax': 'Error: 598',\n",
       " 'ara-unsecret': 'Error: 598',\n",
       " 'ara-aragorn': 'Error: 598',\n",
       " 'ara-robokop': 'Error: 500',\n",
       " 'kp-genetics': 'Unknown: 503',\n",
       " 'kp-molecular': 'Error: 501',\n",
       " 'ara-improving': \"Results: 200{'NCBIGene:120892': 'True', 'NCBIGene:11315': 'True', 'NCBIGene:110357': 'False'}\",\n",
       " 'kp-icees': 'ARS Error: 200',\n",
       " 'kp-textmining': 'No Results: 200',\n",
       " 'ara-aragorn-exp': 'Error: 404',\n",
       " 'ara-ncats': 'Unknown: 503',\n",
       " 'kp-cohd': 'Error: 400'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NCBIGene:120892': 'True',\n",
       " 'NCBIGene:11315': 'True',\n",
       " 'NCBIGene:110357': 'False'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'test' + str(dict3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

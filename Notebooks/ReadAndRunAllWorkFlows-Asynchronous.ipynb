{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and Save Async Query Status in CSV for all Workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Read all the JSON files for all the workflows and print out the messages and query status to a CSV file**\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the modules. NB: submit_run_ars_modules contains all the modules to submit job to ARAX\n",
    "\n",
    "import json\n",
    "import requests\n",
    "from gamma_viewer import GammaViewer\n",
    "from IPython.display import display\n",
    "#from submit_run_ars_modules import submit_to_ars, submit_to_devars, printjson, retrieve_devars_results\n",
    "import glob \n",
    "import os\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "from os import path\n",
    "from datetime import datetime\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_list(_2d_list):\n",
    "    flat_list = []\n",
    "    # Iterate through the outer list\n",
    "    for element in _2d_list:\n",
    "        if type(element) is list:\n",
    "            # If the element is of type list, iterate through the sublist\n",
    "            for item in element:\n",
    "                flat_list.append(item)\n",
    "        else:\n",
    "            flat_list.append(element)\n",
    "    return flat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_to_ars(m,ars_url='https://ars-dev.transltr.io/ars/api',arax_url='https://arax.ncats.io'):\n",
    "    submit_url=f'{ars_url}/submit'\n",
    "    response = requests.post(submit_url,json=m)\n",
    "    try:\n",
    "        message_id = response.json()['pk']\n",
    "    except:\n",
    "        print('fail')\n",
    "        message_id = None\n",
    "    print(f'{arax_url}/?source=ARS&id={message_id}')\n",
    "    return message_id\n",
    "\n",
    "##https://ars.ci.transltr.io/ars/api\n",
    "\n",
    "def retrieve_ars_results(mid, name, check_sheet, ars_url='https://ars-dev.transltr.io/ars/api'):\n",
    "    pk = 'https://arax.ncats.io/?source=ARS&id=' + mid\n",
    "    message_url = f'{ars_url}/messages/{mid}?trace=y'\n",
    "    response = requests.get(message_url)\n",
    "    j = response.json()\n",
    "    print( j['status'] )\n",
    "    results = {}\n",
    "    dictionary = {}\n",
    "    dictionary_2 = {}\n",
    "    dict3 = {}\n",
    "    for child in j['children']:\n",
    "        print(child['status'])\n",
    "        error_code = child['code']\n",
    "        \n",
    "        if child['status']  == 'Done':\n",
    "            childmessage_id = child['message']\n",
    "            child_url = f'{ars_url}/messages/{childmessage_id}'\n",
    "            try:\n",
    "                child_response = requests.get(child_url).json()\n",
    "                nresults = len(child_response['fields']['data']['message']['results'])\n",
    "                if nresults > 0:\n",
    "                    results[child['actor']['agent']] = {'message':child_response['fields']['data']['message']}\n",
    "                    \n",
    "                    if name in list(check_sheet.Workflow):\n",
    "                        print(name)\n",
    "                        dfy = check_sheet[check_sheet['Workflow']== name]\n",
    "\n",
    "                        dfy.reset_index(drop=True)\n",
    "\n",
    "                        for index,curie_id in enumerate(dfy.Curie):\n",
    "                            print(index,curie_id)\n",
    "                            node_num = dfy.iloc[index][3]\n",
    "                            query_id = curie_id\n",
    "                            if np.isnan(dfy.iloc[index][2]) == True:\n",
    "                                len_check = len(child_response['fields']['data']['message']['results'])\n",
    "                            else:\n",
    "                                len_check = dfy.iloc[index][2]\n",
    "\n",
    "                            #print(node_num, query_id, len_check)\n",
    "\n",
    "                            locs = []\n",
    "                            for x, val in enumerate(child_response['fields']['data']['message']['results']):\n",
    "                                #print(val)\n",
    "\n",
    "                                if x < len_check:\n",
    "\n",
    "                                    if query_id in val['node_bindings'][node_num][0]['id']:\n",
    "                                        locs.append(x)\n",
    "                            if not locs:\n",
    "                                check_result = f'False'\n",
    "                                print(check_result)\n",
    "                                #pass\n",
    "                            else:\n",
    "                                check_result = f'True'\n",
    "                                print('curie id:', query_id, ': INCLUDED at postion N ==', locs, 'on', node_num)\n",
    "\n",
    "                            dict3[curie_id] = check_result    \n",
    "\n",
    "                if child_response['fields']['data']['message']['knowledge_graph']['edges']:\n",
    "                    if child_response['fields']['data']['message']['knowledge_graph']['edges'].keys():\n",
    "                            edge_ex = child_response['fields']['data']['message']['knowledge_graph']['edges']\n",
    "                            test_att_values =[]\n",
    "                            for val in child_response['fields']['data']['message']['knowledge_graph']['edges'].keys():\n",
    "                                #print(val)\n",
    "                                \n",
    "                                for tx in edge_ex[val]['attributes']:\n",
    "                                    if (tx['attribute_type_id'] == 'biolink:primary_knowledge_source') or (tx['attribute_type_id'] == 'biolink:original_knowledge_source') or (tx['attribute_type_id'] == 'biolink:aggregator_knowledge_source') :\n",
    "                                        \n",
    "                                        \n",
    "                                        value_att = tx['value']\n",
    "                        \n",
    "                                        test_att_values.append(value_att)\n",
    "                                        test_att = set(flatten_list(test_att_values))\n",
    "                                        \n",
    "                                        \n",
    "                                        dictionary_2[child['actor']['agent']] = test_att\n",
    "                    #else:\n",
    "                        #dictionary_2[child['actor']['agent']] = [] \n",
    "                #else:\n",
    "                   # dictionary_2[child['actor']['agent']] = []\n",
    "            \n",
    "            except Exception as e:\n",
    "                nresults=0\n",
    "                child['status'] = 'ARS Error'\n",
    "                #dictionary_2[child['actor']['agent']] = []\n",
    "                \n",
    "            \n",
    "        \n",
    "        elif child['status'] == 'Error':\n",
    "            nresults=0\n",
    "            childmessage_id = child['message']\n",
    "            child_url = f'{ars_url}/messages/{childmessage_id}'\n",
    "            try:\n",
    "                child_response = requests.get(child_url).json()\n",
    "                results[child['actor']['agent']] = {'message':child_response['fields']['data']['message']}\n",
    "                #dictionary_2[child['actor']['agent']] = []\n",
    "            except Exception as e:\n",
    "                #print(e)\n",
    "                child['status'] = 'ARS Error'\n",
    "                #dictionary_2[child['actor']['agent']] = []\n",
    "        \n",
    "        \n",
    "        else:\n",
    "            nresults = 0\n",
    "            #dictionary_2[child['actor']['agent']] = []\n",
    "            \n",
    "        dictionary['pk_id'] =  pk  \n",
    "            \n",
    "        if ((child['status'] == 'Done') & (nresults == 0)):\n",
    "            dictionary[child['actor']['agent']] = 'No Results' ': ' + str(error_code)\n",
    "            #test =  [child['actor']['agent'], 'No Results']\n",
    "        elif ((child['status'] == 'ARS Error') & (nresults == 0)):\n",
    "            dictionary[child['actor']['agent']] = 'ARS Error' ': ' + str(error_code)\n",
    "        elif ((child['status'] == 'Error') & (nresults == 0)):\n",
    "            dictionary[child['actor']['agent']] = 'Error' ': ' + str(error_code)\n",
    "            #test =  [child['actor']['agent'], 'ARS Error']\n",
    "        elif ((child['status'] == 'Done') & (nresults != 0)):\n",
    "            #test =  [child['actor']['agent'], 'Results']\n",
    "            dictionary[child['actor']['agent']] = 'Results' ': ' + str(error_code) + ' ' + str(dict3)\n",
    "        elif ((child['status'] == 'Unknown') & (nresults == 0)):\n",
    "            #test =  [child['actor']['agent'], 'Results']\n",
    "            dictionary[child['actor']['agent']] = 'Unknown' ': ' + str(error_code)\n",
    "        \n",
    "        \n",
    "        print(child['actor']['agent'], child['status'], nresults)\n",
    "        #test =  [child['actor']['agent'], child['status'], nresults]\n",
    "        #test2.append(test)\n",
    "    return [dictionary, dictionary_2]\n",
    "\n",
    "\n",
    "#def submit_to_devars(m):\n",
    "#    return submit_to_ars(m,ars_url='https://ars-dev.transltr.io/ars/api',arax_url='https://arax.ncats.io')\n",
    "\n",
    "#def retrieve_devars_results(m):\n",
    "#     return retrieve_ars_results(m,ars_url='https://ars-dev.transltr.io/ars/api')\n",
    "\n",
    "def printjson(j):\n",
    "    print(json.dumps(j,indent=4))\n",
    "    \n",
    "def make_hyperlink(value):\n",
    "    return '=HYPERLINK(\"%s\", \"%s\")' % (value.format(value), value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**The below code reads each JSON files from the Workflows A through D (subdirectories). The queries are submitted to ARAX and output is saved in a dictionary, where the key is the file name of the JSON to denote which query is being run and the values assigned to the key is the query id**\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_sheet = pd.read_csv(\"/Users/priyash/Documents/GitHub/minihackathons/Notebooks/Query results to include or exclude - Sheet1.csv\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Workflow</th>\n",
       "      <th>Curie</th>\n",
       "      <th>N (size of list of results)</th>\n",
       "      <th>Query node ID</th>\n",
       "      <th>Include/Exclude</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A.0_RHOBTB2_direct.json</td>\n",
       "      <td>PUBCHEM.COMPOUND:2950270</td>\n",
       "      <td>10.0</td>\n",
       "      <td>n1</td>\n",
       "      <td>Include</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Note: this example row means that for workflow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B.1_DILI-three-hop-interacts-with.json</td>\n",
       "      <td>CHEBI:41879</td>\n",
       "      <td>500.0</td>\n",
       "      <td>n3</td>\n",
       "      <td>Include</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Equivalent identifiers are equally acceptable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B.1_DILI-three-hop-interacts-with.json</td>\n",
       "      <td>MESH:D000077185</td>\n",
       "      <td>500.0</td>\n",
       "      <td>n3</td>\n",
       "      <td>Include</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Equivalent identifiers are equally acceptable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B.1_DILI-three-hop-interacts-with.json</td>\n",
       "      <td>MESH:D000077385</td>\n",
       "      <td>500.0</td>\n",
       "      <td>n3</td>\n",
       "      <td>Include</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Equivalent identifiers are equally acceptable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B.1_DILI-three-hop-interacts-with.json</td>\n",
       "      <td>MESH:D003474</td>\n",
       "      <td>500.0</td>\n",
       "      <td>n3</td>\n",
       "      <td>Include</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Equivalent identifiers are equally acceptable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B.1_DILI-three-hop-interacts-with.json</td>\n",
       "      <td>RXNORM:40068</td>\n",
       "      <td>500.0</td>\n",
       "      <td>n3</td>\n",
       "      <td>Include</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Equivalent identifiers are equally acceptable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B.1_DILI-three-hop-interacts-with.json</td>\n",
       "      <td>PUBCHEM.COMPOUND:5877</td>\n",
       "      <td>500.0</td>\n",
       "      <td>n3</td>\n",
       "      <td>Include</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Equivalent identifiers are equally acceptable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>B.1_DILI-three-hop-interacts-with.json</td>\n",
       "      <td>PUBCHEM.COMPOUND:5755</td>\n",
       "      <td>500.0</td>\n",
       "      <td>n3</td>\n",
       "      <td>Include</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Equivalent identifiers are equally acceptable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>C.1a_SmallMolecule_real_world_evidence_MultScl...</td>\n",
       "      <td>MONDO:0005301</td>\n",
       "      <td>100.0</td>\n",
       "      <td>n00</td>\n",
       "      <td>include</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>C.2a_Imatinib_MultSclerosis_GeneSet_and_SmallM...</td>\n",
       "      <td>CHEBI:45783</td>\n",
       "      <td>100.0</td>\n",
       "      <td>n3</td>\n",
       "      <td>include</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>C.2b_Etanercept_MultSclerosis_GeneSet_and_Smal...</td>\n",
       "      <td>CHEBI:4875</td>\n",
       "      <td>100.0</td>\n",
       "      <td>n3</td>\n",
       "      <td>include</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>C.2c_Natalizumab_MultSclerosis_GeneSet_and_Sma...</td>\n",
       "      <td>CHEMBL.COMPOUND:CHEMBL1201607</td>\n",
       "      <td>100.0</td>\n",
       "      <td>n3</td>\n",
       "      <td>include</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>D.1_parkinsons-crohns.json</td>\n",
       "      <td>NCBIGene:120892</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n01</td>\n",
       "      <td>include</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LRRK2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>D.1_parkinsons-crohns.json</td>\n",
       "      <td>NCBIGene:11315</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n01</td>\n",
       "      <td>include</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PARK7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>D.1_parkinsons-crohns.json</td>\n",
       "      <td>NCBIGene:110357</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n01</td>\n",
       "      <td>include</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MOD2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>D.2_ssri-heart-disease.json</td>\n",
       "      <td>NCBIGene:3988</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n01</td>\n",
       "      <td>include</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LIPA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>D.2_ssri-heart-disease.json</td>\n",
       "      <td>NCBIGene:5627</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n01</td>\n",
       "      <td>include</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PROS1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>D.2_ssri-heart-disease.json</td>\n",
       "      <td>NCBIGene:7043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n01</td>\n",
       "      <td>include</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TGFB3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>D.4_tryptophan-kyurenine.json</td>\n",
       "      <td>REACT:R-HSA-888614</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n02</td>\n",
       "      <td>include</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IDO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>D.4_tryptophan-kyurenine.json</td>\n",
       "      <td>KEGG:1.13.11.52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n02</td>\n",
       "      <td>include</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IDO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>D.4_tryptophan-kyurenine.json</td>\n",
       "      <td>REACT:R-HSA-888614</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n03</td>\n",
       "      <td>include</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IDO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>D.4_tryptophan-kyurenine.json</td>\n",
       "      <td>KEGG:1.13.11.52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n03</td>\n",
       "      <td>include</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IDO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>D.6_metformin-ferritin.json</td>\n",
       "      <td>UniProtKB:P54646</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n01</td>\n",
       "      <td>include</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AAPK protein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>D.6_metformin-ferritin.json</td>\n",
       "      <td>NCBIGene:5563</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n01</td>\n",
       "      <td>include</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AMPK gene</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>D.6_metformin-ferritin.json</td>\n",
       "      <td>UniProtKB:P42345</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n02</td>\n",
       "      <td>include</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MTOR protein</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Workflow  \\\n",
       "0                             A.0_RHOBTB2_direct.json   \n",
       "1              B.1_DILI-three-hop-interacts-with.json   \n",
       "2              B.1_DILI-three-hop-interacts-with.json   \n",
       "3              B.1_DILI-three-hop-interacts-with.json   \n",
       "4              B.1_DILI-three-hop-interacts-with.json   \n",
       "5              B.1_DILI-three-hop-interacts-with.json   \n",
       "6              B.1_DILI-three-hop-interacts-with.json   \n",
       "7              B.1_DILI-three-hop-interacts-with.json   \n",
       "8   C.1a_SmallMolecule_real_world_evidence_MultScl...   \n",
       "9   C.2a_Imatinib_MultSclerosis_GeneSet_and_SmallM...   \n",
       "10  C.2b_Etanercept_MultSclerosis_GeneSet_and_Smal...   \n",
       "11  C.2c_Natalizumab_MultSclerosis_GeneSet_and_Sma...   \n",
       "12                         D.1_parkinsons-crohns.json   \n",
       "13                         D.1_parkinsons-crohns.json   \n",
       "14                         D.1_parkinsons-crohns.json   \n",
       "15                        D.2_ssri-heart-disease.json   \n",
       "16                        D.2_ssri-heart-disease.json   \n",
       "17                        D.2_ssri-heart-disease.json   \n",
       "18                      D.4_tryptophan-kyurenine.json   \n",
       "19                      D.4_tryptophan-kyurenine.json   \n",
       "20                      D.4_tryptophan-kyurenine.json   \n",
       "21                      D.4_tryptophan-kyurenine.json   \n",
       "22                        D.6_metformin-ferritin.json   \n",
       "23                        D.6_metformin-ferritin.json   \n",
       "24                        D.6_metformin-ferritin.json   \n",
       "\n",
       "                            Curie  N (size of list of results) Query node ID  \\\n",
       "0        PUBCHEM.COMPOUND:2950270                         10.0            n1   \n",
       "1                     CHEBI:41879                        500.0            n3   \n",
       "2                 MESH:D000077185                        500.0            n3   \n",
       "3                 MESH:D000077385                        500.0            n3   \n",
       "4                    MESH:D003474                        500.0            n3   \n",
       "5                    RXNORM:40068                        500.0            n3   \n",
       "6           PUBCHEM.COMPOUND:5877                        500.0            n3   \n",
       "7           PUBCHEM.COMPOUND:5755                        500.0            n3   \n",
       "8                   MONDO:0005301                        100.0           n00   \n",
       "9                     CHEBI:45783                        100.0            n3   \n",
       "10                     CHEBI:4875                        100.0            n3   \n",
       "11  CHEMBL.COMPOUND:CHEMBL1201607                        100.0            n3   \n",
       "12                NCBIGene:120892                          NaN           n01   \n",
       "13                 NCBIGene:11315                          NaN           n01   \n",
       "14                NCBIGene:110357                          NaN           n01   \n",
       "15                  NCBIGene:3988                          NaN           n01   \n",
       "16                  NCBIGene:5627                          NaN           n01   \n",
       "17                  NCBIGene:7043                          NaN           n01   \n",
       "18             REACT:R-HSA-888614                          NaN           n02   \n",
       "19                KEGG:1.13.11.52                          NaN           n02   \n",
       "20             REACT:R-HSA-888614                          NaN           n03   \n",
       "21                KEGG:1.13.11.52                          NaN           n03   \n",
       "22               UniProtKB:P54646                          NaN           n01   \n",
       "23                  NCBIGene:5563                          NaN           n01   \n",
       "24               UniProtKB:P42345                          NaN           n02   \n",
       "\n",
       "   Include/Exclude  Unnamed: 5  \\\n",
       "0          Include         NaN   \n",
       "1          Include         NaN   \n",
       "2          Include         NaN   \n",
       "3          Include         NaN   \n",
       "4          Include         NaN   \n",
       "5          Include         NaN   \n",
       "6          Include         NaN   \n",
       "7          Include         NaN   \n",
       "8          include         NaN   \n",
       "9          include         NaN   \n",
       "10         include         NaN   \n",
       "11         include         NaN   \n",
       "12         include         NaN   \n",
       "13         include         NaN   \n",
       "14         include         NaN   \n",
       "15         include         NaN   \n",
       "16         include         NaN   \n",
       "17         include         NaN   \n",
       "18         include         NaN   \n",
       "19         include         NaN   \n",
       "20         include         NaN   \n",
       "21         include         NaN   \n",
       "22         include         NaN   \n",
       "23         include         NaN   \n",
       "24         include         NaN   \n",
       "\n",
       "                                           Unnamed: 6  \n",
       "0   Note: this example row means that for workflow...  \n",
       "1       Equivalent identifiers are equally acceptable  \n",
       "2       Equivalent identifiers are equally acceptable  \n",
       "3       Equivalent identifiers are equally acceptable  \n",
       "4       Equivalent identifiers are equally acceptable  \n",
       "5       Equivalent identifiers are equally acceptable  \n",
       "6       Equivalent identifiers are equally acceptable  \n",
       "7       Equivalent identifiers are equally acceptable  \n",
       "8                                                 NaN  \n",
       "9                                                 NaN  \n",
       "10                                                NaN  \n",
       "11                                                NaN  \n",
       "12                                              LRRK2  \n",
       "13                                              PARK7  \n",
       "14                                               MOD2  \n",
       "15                                               LIPA  \n",
       "16                                              PROS1  \n",
       "17                                              TGFB3  \n",
       "18                                                IDO  \n",
       "19                                                IDO  \n",
       "20                                                IDO  \n",
       "21                                                IDO  \n",
       "22                                       AAPK protein  \n",
       "23                                          AMPK gene  \n",
       "24                                       MTOR protein  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/priyash/Documents/GitHub/minihackathons/2021-12_demo/workflowA/A.0_RHOBTB2_direct.json\n",
      "A.0_RHOBTB2_direct\n",
      "https://arax.ncats.io/?source=ARS&id=c12bccf0-322f-4ff9-9756-9c27e3092b19\n",
      "Done\n",
      "Done\n",
      "ara-aragorn Done 0\n",
      "Done\n",
      "ara-arax Done 0\n",
      "Done\n",
      "ara-bte Done 0\n",
      "/Users/priyash/Documents/GitHub/minihackathons/2021-12_demo/workflowA/A.0_RHOBTB2_direct_inverse.json\n",
      "A.0_RHOBTB2_direct_inverse\n",
      "https://arax.ncats.io/?source=ARS&id=aac45ec7-6142-40a6-9626-f70eb793d707\n",
      "Done\n",
      "Done\n",
      "ara-arax Done 4\n",
      "Done\n",
      "ara-aragorn Done 4\n",
      "Done\n",
      "ara-bte Done 1\n",
      "/Users/priyash/Documents/GitHub/minihackathons/2021-12_demo/workflowA/A.2_RHOBTB2_twohop.json\n",
      "A.2_RHOBTB2_twohop\n",
      "https://arax.ncats.io/?source=ARS&id=9b9ac418-7b96-4d14-b8bc-92822baefb6d\n",
      "Running\n",
      "Running\n",
      "ara-aragorn Running 0\n",
      "Running\n",
      "ara-arax Running 0\n",
      "Running\n",
      "ara-bte Running 0\n",
      "/Users/priyash/Documents/GitHub/minihackathons/2021-12_demo/workflowA/A.2a_expanded_RHOBTB2_twohop.json\n",
      "A.2a_expanded_RHOBTB2_twohop\n",
      "https://arax.ncats.io/?source=ARS&id=ab0e1d74-4ec2-43a8-8660-da315e6d6f35\n",
      "Done\n",
      "Done\n",
      "ara-aragorn Done 602\n",
      "Done\n",
      "ara-arax Done 43\n",
      "Done\n",
      "ara-bte Done 35\n",
      "/Users/priyash/Documents/GitHub/minihackathons/2021-12_demo/workflowB/B.2b_DILI-fourth-one-hop-from-MESH_D000077185_Resveratrol.json\n",
      "B.2b_DILI-fourth-one-hop-from-MESH_D000077185_Resveratrol\n",
      "https://arax.ncats.io/?source=ARS&id=75255413-5def-4d2d-a0fb-47ad080d7874\n",
      "Running\n",
      "Running\n",
      "ara-aragorn Running 0\n",
      "Done\n",
      "ara-arax Done 500\n",
      "Running\n",
      "ara-bte Running 0\n",
      "/Users/priyash/Documents/GitHub/minihackathons/2021-12_demo/workflowB/B.3b_DILI-two-hop-drug.json\n",
      "B.3b_DILI-two-hop-drug\n",
      "https://arax.ncats.io/?source=ARS&id=da1d9d09-a3b1-4b9f-adab-43b0387dd08b\n",
      "Running\n",
      "Error\n",
      "ara-aragorn Error 0\n",
      "Running\n",
      "ara-arax Running 0\n",
      "Running\n",
      "ara-bte Running 0\n",
      "/Users/priyash/Documents/GitHub/minihackathons/2021-12_demo/workflowB/B.1_DILI-three-hop.json\n",
      "B.1_DILI-three-hop\n",
      "https://arax.ncats.io/?source=ARS&id=4a9c3040-8909-47d3-9e6a-f03319cff3f5\n",
      "Running\n",
      "Error\n",
      "ara-aragorn Error 0\n",
      "Running\n",
      "ara-arax Running 0\n",
      "Running\n",
      "ara-bte Running 0\n",
      "/Users/priyash/Documents/GitHub/minihackathons/2021-12_demo/workflowB/B.2a_DILI-fourth-one-hop-from-CHEBI_41879_Dexamethasone.json\n",
      "B.2a_DILI-fourth-one-hop-from-CHEBI_41879_Dexamethasone\n",
      "https://arax.ncats.io/?source=ARS&id=649e0849-7f73-4d60-b032-5cd7c2e8de8e\n",
      "Running\n",
      "Done\n",
      "ara-aragorn Done 881\n",
      "Done\n",
      "ara-arax Done 500\n",
      "Running\n",
      "ara-bte Running 0\n",
      "/Users/priyash/Documents/GitHub/minihackathons/2021-12_demo/workflowB/B.3a_DILI-two-hop-chemical-entity.json\n",
      "B.3a_DILI-two-hop-chemical-entity\n",
      "https://arax.ncats.io/?source=ARS&id=fb49888d-d906-4b42-9128-b90639700299\n",
      "Running\n",
      "Running\n",
      "ara-aragorn Running 0\n",
      "Running\n",
      "ara-arax Running 0\n",
      "Running\n",
      "ara-bte Running 0\n",
      "/Users/priyash/Documents/GitHub/minihackathons/2021-12_demo/workflowB/B.2d_DILI-fourth-one-hop-from-PUBCHEM.COMPOUND_5877_Methylprednisone.json\n",
      "B.2d_DILI-fourth-one-hop-from-PUBCHEM.COMPOUND_5877_Methylprednisone\n",
      "https://arax.ncats.io/?source=ARS&id=517e05a6-1087-4845-9766-d4b190c95446\n",
      "Running\n",
      "Running\n",
      "ara-aragorn Running 0\n",
      "Done\n",
      "ara-arax Done 500\n",
      "Running\n",
      "ara-bte Running 0\n",
      "/Users/priyash/Documents/GitHub/minihackathons/2021-12_demo/workflowB/B.2c_DILI-fourth-one-hop-from-MESH_D000077385_Silybin.json\n",
      "B.2c_DILI-fourth-one-hop-from-MESH_D000077385_Silybin\n",
      "https://arax.ncats.io/?source=ARS&id=32bc9dd4-0569-467e-b289-ade162f487b2\n",
      "Done\n",
      "Done\n",
      "ara-aragorn Done 358\n",
      "Done\n",
      "ara-arax Done 500\n",
      "Done\n",
      "ara-bte Done 167\n",
      "/Users/priyash/Documents/GitHub/minihackathons/2021-12_demo/workflowB/B.2f_DILI-fourth-one-hop-from-CHEMBL.COMPOUND_CHEMBL50_Quercetin.json\n",
      "B.2f_DILI-fourth-one-hop-from-CHEMBL.COMPOUND_CHEMBL50_Quercetin\n",
      "https://arax.ncats.io/?source=ARS&id=1ae0be50-9a66-4036-bb1e-96c32a737d4e\n",
      "Done\n",
      "Done\n",
      "ara-aragorn Done 1106\n",
      "Done\n",
      "ara-arax Done 500\n",
      "Done\n",
      "ara-bte Done 468\n",
      "/Users/priyash/Documents/GitHub/minihackathons/2021-12_demo/workflowB/B.2e_DILI-fourth-one-hop-from-PUBCHEM.COMPOUND_5865_Prednisone.json\n",
      "B.2e_DILI-fourth-one-hop-from-PUBCHEM.COMPOUND_5865_Prednisone\n",
      "https://arax.ncats.io/?source=ARS&id=4e9ab689-1400-4365-be4f-d32adfa8bb67\n",
      "Running\n",
      "Done\n",
      "ara-aragorn Done 652\n",
      "Done\n",
      "ara-arax Done 500\n",
      "Running\n",
      "ara-bte Running 0\n",
      "/Users/priyash/Documents/GitHub/minihackathons/2021-12_demo/workflowD/D.1_parkinsons-crohns.json\n",
      "D.1_parkinsons-crohns\n",
      "https://arax.ncats.io/?source=ARS&id=6e52a2c9-e99b-416f-a2e5-bad1306e02ae\n",
      "Running\n",
      "Running\n",
      "ara-aragorn Running 0\n",
      "Running\n",
      "ara-arax Running 0\n",
      "Running\n",
      "ara-bte Running 0\n",
      "/Users/priyash/Documents/GitHub/minihackathons/2021-12_demo/workflowD/D.3_ssri-heart-disease-one-hop.json\n",
      "D.3_ssri-heart-disease-one-hop\n",
      "https://arax.ncats.io/?source=ARS&id=a7b9b3d0-376e-4f83-98eb-b20756f7bc6e\n",
      "Done\n",
      "Done\n",
      "ara-aragorn Done 264\n",
      "Done\n",
      "ara-arax Done 38\n",
      "Done\n",
      "ara-bte Done 9\n",
      "/Users/priyash/Documents/GitHub/minihackathons/2021-12_demo/workflowD/D.6_metformin-ferritin.json\n",
      "D.6_metformin-ferritin\n",
      "https://arax.ncats.io/?source=ARS&id=be771cb7-07c7-4284-8ce4-fcdf441d6666\n",
      "Running\n",
      "Running\n",
      "ara-aragorn Running 0\n",
      "Running\n",
      "ara-arax Running 0\n",
      "Running\n",
      "ara-bte Running 0\n",
      "/Users/priyash/Documents/GitHub/minihackathons/2021-12_demo/workflowD/D.2_ssri-heart-disease.json\n",
      "D.2_ssri-heart-disease\n",
      "https://arax.ncats.io/?source=ARS&id=f977e699-90e1-4aee-bddf-1943fbb3debf\n",
      "Running\n",
      "Error\n",
      "ara-aragorn Error 0\n",
      "Running\n",
      "ara-arax Running 0\n",
      "Running\n",
      "ara-bte Running 0\n",
      "/Users/priyash/Documents/GitHub/minihackathons/2021-12_demo/workflowD/D.4_tryptophan-kynurenine.json\n",
      "D.4_tryptophan-kynurenine\n",
      "https://arax.ncats.io/?source=ARS&id=3d216e64-534c-4f53-87d3-149624109005\n",
      "Running\n",
      "Done\n",
      "ara-aragorn Done 0\n",
      "Running\n",
      "ara-arax Running 0\n",
      "Done\n",
      "ara-bte Done 0\n",
      "/Users/priyash/Documents/GitHub/minihackathons/2021-12_demo/workflowC/C.2c_Natalizumab_MultSclerosis_GeneSet_and_SmallMolecule.json\n",
      "C.2c_Natalizumab_MultSclerosis_GeneSet_and_SmallMolecule\n",
      "https://arax.ncats.io/?source=ARS&id=2530e967-f8ac-4135-aefb-76aa8bebd25f\n",
      "Running\n",
      "Running\n",
      "ara-aragorn Running 0\n",
      "Running\n",
      "ara-arax Running 0\n",
      "Running\n",
      "ara-bte Running 0\n",
      "/Users/priyash/Documents/GitHub/minihackathons/2021-12_demo/workflowC/C.1a_SmallMolecule_real_world_evidence_MultSclerosis.json\n",
      "C.1a_SmallMolecule_real_world_evidence_MultSclerosis\n",
      "https://arax.ncats.io/?source=ARS&id=9a4d9109-6cbe-44e4-abcd-937cc2f26327\n",
      "Running\n",
      "Done\n",
      "C.1a_SmallMolecule_real_world_evidence_MultSclerosis.json\n",
      "0 MONDO:0005301\n",
      "curie id: MONDO:0005301 : INCLUDED at postion N == [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99] on n00\n",
      "ara-aragorn Done 211\n",
      "Done\n",
      "C.1a_SmallMolecule_real_world_evidence_MultSclerosis.json\n",
      "0 MONDO:0005301\n",
      "curie id: MONDO:0005301 : INCLUDED at postion N == [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 66, 68, 73, 76, 77, 78, 80, 82, 85, 87] on n00\n",
      "ara-arax Done 88\n",
      "Running\n",
      "ara-bte Running 0\n",
      "/Users/priyash/Documents/GitHub/minihackathons/2021-12_demo/workflowC/C.3a_MultSclerosis_related_to_Nimodipine.json\n",
      "C.3a_MultSclerosis_related_to_Nimodipine\n",
      "https://arax.ncats.io/?source=ARS&id=8838537a-432d-47f4-9d84-572cc67086fc\n",
      "Done\n",
      "Done\n",
      "ara-aragorn Done 0\n",
      "Done\n",
      "ara-arax Done 1\n",
      "Done\n",
      "ara-bte Done 0\n",
      "/Users/priyash/Documents/GitHub/minihackathons/2021-12_demo/workflowC/C.2a_Imatinib_MultSclerosis_GeneSet_and_SmallMolecule.json\n",
      "C.2a_Imatinib_MultSclerosis_GeneSet_and_SmallMolecule\n",
      "https://arax.ncats.io/?source=ARS&id=6520162f-c818-4509-be20-65ac11dafdd2\n",
      "Running\n",
      "Running\n",
      "ara-arax Running 0\n",
      "Running\n",
      "ara-aragorn Running 0\n",
      "Running\n",
      "ara-bte Running 0\n",
      "/Users/priyash/Documents/GitHub/minihackathons/2021-12_demo/workflowC/C.4a_Drugs_CNS_myelination.json\n",
      "C.4a_Drugs_CNS_myelination\n",
      "https://arax.ncats.io/?source=ARS&id=76e4ded4-089a-4efd-818a-bb78fbab955a\n",
      "Done\n",
      "Error\n",
      "ara-aragorn Error 0\n",
      "Done\n",
      "ara-arax Done 0\n",
      "Done\n",
      "ara-bte Done 0\n"
     ]
    }
   ],
   "source": [
    "PATH = r'/Users/priyash/Documents/GitHub/minihackathons/2021-12_demo'\n",
    "EXT = \"*.json\"\n",
    "dict_workflows = {}\n",
    "for root, dirs, files in os.walk(PATH): # step 1: accessing file\n",
    "    for name in files:\n",
    "        \n",
    "        if name.endswith((\".json\")):\n",
    "            if (name == 'C.1_Template_SmallMolecule_real_world_evidence_Disease.json') or (name == 'C.2_Template_Drug_Disease_GeneSet_interacts_with_SmallMolecule.json') or (name == 'C.3_Template_Disease_related_to_Drug.json'):\n",
    "                pass\n",
    "            else:\n",
    "                file_read = path.join(root, name)\n",
    "                dir_name = (os.path.splitext(os.path.basename(root))[0])\n",
    "                print(file_read)\n",
    "\n",
    "                filename = (os.path.splitext(os.path.basename(file_read))[0])\n",
    "                print(filename)\n",
    "                with open(file_read,'r') as inf:\n",
    "                    query = json.load(inf)\n",
    "\n",
    "                    kcresult = submit_to_ars(query)\n",
    "\n",
    "                    sleep(200)\n",
    "\n",
    "                    result_status = retrieve_ars_results(kcresult, name, check_sheet)\n",
    "\n",
    "\n",
    "                    dict_workflows[filename] = kcresult\n",
    "\n",
    "                    sleep(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Codes below are for recording messages and generating outout as csv\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep(4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A.0_RHOBTB2_direct': 'c12bccf0-322f-4ff9-9756-9c27e3092b19',\n",
       " 'A.0_RHOBTB2_direct_inverse': 'aac45ec7-6142-40a6-9626-f70eb793d707',\n",
       " 'A.2_RHOBTB2_twohop': '9b9ac418-7b96-4d14-b8bc-92822baefb6d',\n",
       " 'A.2a_expanded_RHOBTB2_twohop': 'ab0e1d74-4ec2-43a8-8660-da315e6d6f35',\n",
       " 'B.2b_DILI-fourth-one-hop-from-MESH_D000077185_Resveratrol': '75255413-5def-4d2d-a0fb-47ad080d7874',\n",
       " 'B.3b_DILI-two-hop-drug': 'da1d9d09-a3b1-4b9f-adab-43b0387dd08b',\n",
       " 'B.1_DILI-three-hop': '4a9c3040-8909-47d3-9e6a-f03319cff3f5',\n",
       " 'B.2a_DILI-fourth-one-hop-from-CHEBI_41879_Dexamethasone': '649e0849-7f73-4d60-b032-5cd7c2e8de8e',\n",
       " 'B.3a_DILI-two-hop-chemical-entity': 'fb49888d-d906-4b42-9128-b90639700299',\n",
       " 'B.2d_DILI-fourth-one-hop-from-PUBCHEM.COMPOUND_5877_Methylprednisone': '517e05a6-1087-4845-9766-d4b190c95446',\n",
       " 'B.2c_DILI-fourth-one-hop-from-MESH_D000077385_Silybin': '32bc9dd4-0569-467e-b289-ade162f487b2',\n",
       " 'B.2f_DILI-fourth-one-hop-from-CHEMBL.COMPOUND_CHEMBL50_Quercetin': '1ae0be50-9a66-4036-bb1e-96c32a737d4e',\n",
       " 'B.2e_DILI-fourth-one-hop-from-PUBCHEM.COMPOUND_5865_Prednisone': '4e9ab689-1400-4365-be4f-d32adfa8bb67',\n",
       " 'D.1_parkinsons-crohns': '6e52a2c9-e99b-416f-a2e5-bad1306e02ae',\n",
       " 'D.3_ssri-heart-disease-one-hop': 'a7b9b3d0-376e-4f83-98eb-b20756f7bc6e',\n",
       " 'D.6_metformin-ferritin': 'be771cb7-07c7-4284-8ce4-fcdf441d6666',\n",
       " 'D.2_ssri-heart-disease': 'f977e699-90e1-4aee-bddf-1943fbb3debf',\n",
       " 'D.4_tryptophan-kynurenine': '3d216e64-534c-4f53-87d3-149624109005',\n",
       " 'C.2c_Natalizumab_MultSclerosis_GeneSet_and_SmallMolecule': '2530e967-f8ac-4135-aefb-76aa8bebd25f',\n",
       " 'C.1a_SmallMolecule_real_world_evidence_MultSclerosis': '9a4d9109-6cbe-44e4-abcd-937cc2f26327',\n",
       " 'C.3a_MultSclerosis_related_to_Nimodipine': '8838537a-432d-47f4-9d84-572cc67086fc',\n",
       " 'C.2a_Imatinib_MultSclerosis_GeneSet_and_SmallMolecule': '6520162f-c818-4509-be20-65ac11dafdd2',\n",
       " 'C.4a_Drugs_CNS_myelination': '76e4ded4-089a-4efd-818a-bb78fbab955a'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A.0_RHOBTB2_direct c12bccf0-322f-4ff9-9756-9c27e3092b19\n",
      "Done\n",
      "Done\n",
      "ara-aragorn Done 0\n",
      "Done\n",
      "ara-arax Done 0\n",
      "Done\n",
      "ara-bte Done 0\n",
      "A.0_RHOBTB2_direct_inverse aac45ec7-6142-40a6-9626-f70eb793d707\n",
      "Done\n",
      "Done\n",
      "ara-arax Done 4\n",
      "Done\n",
      "ara-aragorn Done 4\n",
      "Done\n",
      "ara-bte Done 1\n",
      "A.2_RHOBTB2_twohop 9b9ac418-7b96-4d14-b8bc-92822baefb6d\n",
      "Running\n",
      "Running\n",
      "ara-aragorn Running 0\n",
      "Done\n",
      "ara-arax Done 500\n",
      "Running\n",
      "ara-bte Running 0\n",
      "A.2a_expanded_RHOBTB2_twohop ab0e1d74-4ec2-43a8-8660-da315e6d6f35\n",
      "Done\n",
      "Done\n",
      "ara-aragorn Done 602\n",
      "Done\n",
      "ara-arax Done 43\n",
      "Done\n",
      "ara-bte Done 35\n",
      "B.2b_DILI-fourth-one-hop-from-MESH_D000077185_Resveratrol 75255413-5def-4d2d-a0fb-47ad080d7874\n",
      "Running\n",
      "Running\n",
      "ara-aragorn Running 0\n",
      "Done\n",
      "ara-arax Done 500\n",
      "Running\n",
      "ara-bte Running 0\n",
      "B.3b_DILI-two-hop-drug da1d9d09-a3b1-4b9f-adab-43b0387dd08b\n",
      "Done\n",
      "Error\n",
      "ara-aragorn Error 0\n",
      "Done\n",
      "ara-arax Done 500\n",
      "Done\n",
      "ara-bte Done 0\n",
      "B.1_DILI-three-hop 4a9c3040-8909-47d3-9e6a-f03319cff3f5\n",
      "Done\n",
      "Error\n",
      "ara-aragorn Error 0\n",
      "Done\n",
      "ara-arax Done 500\n",
      "Done\n",
      "ara-bte Done 0\n",
      "B.2a_DILI-fourth-one-hop-from-CHEBI_41879_Dexamethasone 649e0849-7f73-4d60-b032-5cd7c2e8de8e\n",
      "Running\n",
      "Done\n",
      "ara-aragorn Done 881\n",
      "Done\n",
      "ara-arax Done 500\n",
      "Running\n",
      "ara-bte Running 0\n",
      "B.3a_DILI-two-hop-chemical-entity fb49888d-d906-4b42-9128-b90639700299\n",
      "Running\n",
      "Running\n",
      "ara-aragorn Running 0\n",
      "Done\n",
      "ara-arax Done 500\n",
      "Done\n",
      "ara-bte Done 2\n",
      "B.2d_DILI-fourth-one-hop-from-PUBCHEM.COMPOUND_5877_Methylprednisone 517e05a6-1087-4845-9766-d4b190c95446\n",
      "Running\n",
      "Running\n",
      "ara-aragorn Running 0\n",
      "Done\n",
      "ara-arax Done 500\n",
      "Running\n",
      "ara-bte Running 0\n",
      "B.2c_DILI-fourth-one-hop-from-MESH_D000077385_Silybin 32bc9dd4-0569-467e-b289-ade162f487b2\n",
      "Done\n",
      "Done\n",
      "ara-aragorn Done 358\n",
      "Done\n",
      "ara-arax Done 500\n",
      "Done\n",
      "ara-bte Done 167\n",
      "B.2f_DILI-fourth-one-hop-from-CHEMBL.COMPOUND_CHEMBL50_Quercetin 1ae0be50-9a66-4036-bb1e-96c32a737d4e\n",
      "Done\n",
      "Done\n",
      "ara-aragorn Done 1106\n",
      "Done\n",
      "ara-arax Done 500\n",
      "Done\n",
      "ara-bte Done 468\n",
      "B.2e_DILI-fourth-one-hop-from-PUBCHEM.COMPOUND_5865_Prednisone 4e9ab689-1400-4365-be4f-d32adfa8bb67\n",
      "Running\n",
      "Done\n",
      "ara-aragorn Done 652\n",
      "Done\n",
      "ara-arax Done 500\n",
      "Running\n",
      "ara-bte Running 0\n",
      "D.1_parkinsons-crohns 6e52a2c9-e99b-416f-a2e5-bad1306e02ae\n",
      "Running\n",
      "Running\n",
      "ara-aragorn Running 0\n",
      "Done\n",
      "D.1_parkinsons-crohns.json\n",
      "0 NCBIGene:120892\n",
      "False\n",
      "1 NCBIGene:11315\n",
      "False\n",
      "2 NCBIGene:110357\n",
      "False\n",
      "ara-arax Done 500\n",
      "Running\n",
      "ara-bte Running 0\n",
      "D.3_ssri-heart-disease-one-hop a7b9b3d0-376e-4f83-98eb-b20756f7bc6e\n",
      "Done\n",
      "Done\n",
      "ara-aragorn Done 264\n",
      "Done\n",
      "ara-arax Done 38\n",
      "Done\n",
      "ara-bte Done 9\n",
      "D.6_metformin-ferritin be771cb7-07c7-4284-8ce4-fcdf441d6666\n",
      "Running\n",
      "Running\n",
      "ara-aragorn Running 0\n",
      "Done\n",
      "D.6_metformin-ferritin.json\n",
      "0 UniProtKB:P54646\n",
      "ara-arax ARS Error 0\n",
      "Running\n",
      "ara-bte Running 0\n",
      "D.2_ssri-heart-disease f977e699-90e1-4aee-bddf-1943fbb3debf\n",
      "Done\n",
      "Error\n",
      "ara-aragorn Error 0\n",
      "Done\n",
      "D.2_ssri-heart-disease.json\n",
      "0 NCBIGene:3988\n",
      "False\n",
      "1 NCBIGene:5627\n",
      "False\n",
      "2 NCBIGene:7043\n",
      "False\n",
      "ara-arax Done 500\n",
      "Done\n",
      "D.2_ssri-heart-disease.json\n",
      "0 NCBIGene:3988\n",
      "curie id: NCBIGene:3988 : INCLUDED at postion N == [36, 37, 38, 314, 315, 316] on n01\n",
      "1 NCBIGene:5627\n",
      "False\n",
      "2 NCBIGene:7043\n",
      "False\n",
      "ara-bte Done 483\n",
      "D.4_tryptophan-kynurenine 3d216e64-534c-4f53-87d3-149624109005\n",
      "Running\n",
      "Done\n",
      "ara-aragorn Done 0\n",
      "Running\n",
      "ara-arax Running 0\n",
      "Done\n",
      "ara-bte Done 0\n",
      "C.2c_Natalizumab_MultSclerosis_GeneSet_and_SmallMolecule 2530e967-f8ac-4135-aefb-76aa8bebd25f\n",
      "Done\n",
      "Done\n",
      "C.2c_Natalizumab_MultSclerosis_GeneSet_and_SmallMolecule.json\n",
      "0 CHEMBL.COMPOUND:CHEMBL1201607\n",
      "False\n",
      "ara-aragorn Done 46\n",
      "Done\n",
      "C.2c_Natalizumab_MultSclerosis_GeneSet_and_SmallMolecule.json\n",
      "0 CHEMBL.COMPOUND:CHEMBL1201607\n",
      "curie id: CHEMBL.COMPOUND:CHEMBL1201607 : INCLUDED at postion N == [0, 92] on n3\n",
      "ara-arax Done 100\n",
      "Done\n",
      "C.2c_Natalizumab_MultSclerosis_GeneSet_and_SmallMolecule.json\n",
      "0 CHEMBL.COMPOUND:CHEMBL1201607\n",
      "False\n",
      "ara-bte Done 12\n",
      "C.1a_SmallMolecule_real_world_evidence_MultSclerosis 9a4d9109-6cbe-44e4-abcd-937cc2f26327\n",
      "Done\n",
      "Done\n",
      "C.1a_SmallMolecule_real_world_evidence_MultSclerosis.json\n",
      "0 MONDO:0005301\n",
      "curie id: MONDO:0005301 : INCLUDED at postion N == [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99] on n00\n",
      "ara-aragorn Done 211\n",
      "Done\n",
      "C.1a_SmallMolecule_real_world_evidence_MultSclerosis.json\n",
      "0 MONDO:0005301\n",
      "curie id: MONDO:0005301 : INCLUDED at postion N == [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 66, 68, 73, 76, 77, 78, 80, 82, 85, 87] on n00\n",
      "ara-arax Done 88\n",
      "Done\n",
      "C.1a_SmallMolecule_real_world_evidence_MultSclerosis.json\n",
      "0 MONDO:0005301\n",
      "curie id: MONDO:0005301 : INCLUDED at postion N == [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49] on n00\n",
      "ara-bte Done 50\n",
      "C.3a_MultSclerosis_related_to_Nimodipine 8838537a-432d-47f4-9d84-572cc67086fc\n",
      "Done\n",
      "Done\n",
      "ara-aragorn Done 0\n",
      "Done\n",
      "ara-arax Done 1\n",
      "Done\n",
      "ara-bte Done 0\n",
      "C.2a_Imatinib_MultSclerosis_GeneSet_and_SmallMolecule 6520162f-c818-4509-be20-65ac11dafdd2\n",
      "Running\n",
      "Done\n",
      "C.2a_Imatinib_MultSclerosis_GeneSet_and_SmallMolecule.json\n",
      "0 CHEBI:45783\n",
      "False\n",
      "ara-arax Done 100\n",
      "Running\n",
      "ara-aragorn Running 0\n",
      "Done\n",
      "C.2a_Imatinib_MultSclerosis_GeneSet_and_SmallMolecule.json\n",
      "0 CHEBI:45783\n",
      "False\n",
      "ara-bte Done 2143\n",
      "C.4a_Drugs_CNS_myelination 76e4ded4-089a-4efd-818a-bb78fbab955a\n",
      "Done\n",
      "Error\n",
      "ara-aragorn Error 0\n",
      "Done\n",
      "ara-arax Done 0\n",
      "Done\n",
      "ara-bte Done 0\n"
     ]
    }
   ],
   "source": [
    "workflow_result_messages = {}\n",
    "for keys, val in dict_workflows.items():\n",
    "    name = keys + '.json'\n",
    "    print(keys, val)\n",
    "    \n",
    "    result_status = retrieve_ars_results(val, name, check_sheet)\n",
    "    \n",
    "    workflow_result_messages[keys] = result_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow_result_messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating dataframe for workflows with PK\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#workflow_result_messages['D.4_tryptophan-kynurenine'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Convert mesages to a dataframe\n",
    "col = []\n",
    "final_dict = defaultdict(list)\n",
    "\n",
    "for k in sorted(workflow_result_messages):\n",
    "    print(k)\n",
    "    col.append(k)\n",
    "    \n",
    "    count = 0\n",
    "    if ((len(workflow_result_messages[k][0])==2) & (k != 'D.4_tryptophan-kynurenine')):\n",
    "        workflow_result_messages[k][0].update({'ara-bte': 'running'})\n",
    "    #elif k != 'D.4_tryptophan-kynurenine':\n",
    "        #workflow_result_messages[k][0].update({'ara-arax': 'running'})\n",
    "        \n",
    "    for key, value in workflow_result_messages[k][0].items():\n",
    "        count= count+1\n",
    "        \n",
    "        final_dict[key].append(value)\n",
    "        \n",
    "\n",
    "    final_dict = dict(final_dict)\n",
    "    print(count)\n",
    "    \n",
    "#df = pd.DataFrame.from_dict(final_dict, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow_result_messages['B.2b_DILI-fourth-one-hop-from-MESH_D000077185_Resveratrol'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#workflow_result_messages['D.4_tryptophan-kynurenine'][0].update({'ara-arax': 'running'})\n",
    "workflow_result_messages['B.2b_DILI-fourth-one-hop-from-MESH_D000077185_Resveratrol'][0].update({'ara-aragorn': 'running'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(final_dict).T\n",
    "df.rename(columns=dict(zip(df.columns, col)), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace('ARS Error', 'No Results', regex=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace('{}','',regex=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace('None','still running',regex=True,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating second table with edge attribute source\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow_result_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dict2 = defaultdict(dict)\n",
    "for k in sorted(workflow_result_messages):\n",
    "    print(k)\n",
    "    \n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "\n",
    "    col.append(k)\n",
    "    for key, value in workflow_result_messages[k][1].items():\n",
    "        final_dict2[k][key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_dict2.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dictassemble = []\n",
    "for k, vs in final_dict2.items():\n",
    "    #print(k,vs)\n",
    "    for kv, v in vs.items():\n",
    "        for t in v:\n",
    "            final_dictassemble.append([k,kv,t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dictassemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['Workflow', 'ARS-KPs', 'Values']\n",
    "df2 = pd.DataFrame(final_dictassemble, columns=column_names)\n",
    "df2 = df2.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.Values = df2.Values.apply(lambda x: x[2:-2] if ('[' in x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2test = df2.groupby(['Workflow','Values'])['ARS-KPs'].agg(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2test = pd.DataFrame(df2test.unstack().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2test.drop([''], axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2test.index = df2test.index.map(lambda x: x[2:-2] if ('[' in x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2.replace([], 'None', regex=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2test = df2test.mask(df2test.applymap(type).eq(list) & ~df2test.astype(bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2test = df2test.rename_axis(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2test.columns.name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2test.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infores_catalog = pd.read_csv(\"/Users/priyash/Documents/GitHub/minihackathons/Notebooks/InfoRes Catalog - Translator InfoRes Catalog.csv\", header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infores_catalog = infores_catalog[['id', 'name','translator category','has contributor']]\n",
    "infores_catalog = infores_catalog[:335]\n",
    "dict_map = {}\n",
    "for i in df2test.index.values:\n",
    "    if i in infores_catalog['id'].values:\n",
    "        indices = infores_catalog[infores_catalog['id']==i].index[0]\n",
    "        if pd.notnull(infores_catalog.iloc[indices]['has contributor']):\n",
    "            dict_map[i] = infores_catalog.iloc[indices]['translator category']\n",
    "        else:\n",
    "            dict_map[i] = 'External Source'\n",
    "    else:\n",
    "        dict_map[i] = 'Illegal value'\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "df2test['Translator_Category_Complaint_to_ColL&M_InforesCatalog']=df2test.index.map(dict_map)\n",
    "df2test['sort']=pd.Categorical(df2test['Translator_Category_Complaint_to_ColL&M_InforesCatalog'], [\"KP\", \"ARA\",'External Source', 'Illegal Value'])\n",
    "df2test =df2test.sort_values(['sort'])\n",
    "df2test  = df2test.rename_axis(None)\n",
    "cols = df2test.columns.tolist()\n",
    "cols = [cols[-2]] + cols[:-2]\n",
    "df2test = df2test[cols]\n",
    "df2test['Query Type'] = 'Async'\n",
    "\n",
    "df2test = df2test[['Query Type']+ list(df2test.columns[:-1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Converting the Pk's to hyperlink\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['pk_id'] = df.loc['pk_id'].apply(lambda x: make_hyperlink(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename({'pk_id': 'pk'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Query Type'] = 'Async'\n",
    "\n",
    "df = df[['Query Type']+ list(df.columns[:-1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#date = datetime.now().strftime(\"%Y_%m_%d-%I_%M_%S_%p\")\n",
    "#wks_name = 'Workflow Progress Tracker Asynchronous_' + date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wks_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Pushing dataframe to excel sheet on google drive\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "**Here I am using the google drive API to push the daatframe into an axcel sheet \n",
    "Every individula has the unique credential file that they need to create for google drive API -- \n",
    "\"araxworkflowprogresstesting-2632632db8be.json\" -- is the credential used from my drive. place this json file where\n",
    "the ReadAndRunAllWorkFLows.ipynb will be. NB: i have removed my credntial file for privacy reasons. Always remove\n",
    "the json file before making committs to the repo. To use googe Drive API follow: https://towardsdatascience.com/how-to-manage-files-in-google-drive-with-python-d26471d91ecd**\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Google Drive API\n",
    "\n",
    "**Push the dataframe to a google sheet via google drive API and then format the google spread sheet to add hyperlink to pk's and color the cells\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Push Dataframe 1\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gspread\n",
    "from df2gspread import df2gspread as d2g\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "from gspread_dataframe import set_with_dataframe\n",
    "from gspread_formatting import *\n",
    "import gspread_dataframe as gd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scope = ['https://spreadsheets.google.com/feeds',\n",
    "         'https://www.googleapis.com/auth/drive']\n",
    "credentials = ServiceAccountCredentials.from_json_keyfile_name(\n",
    "    'araxworkflowprogresstesting-2632632db8be.json', scope)\n",
    "gc = gspread.authorize(credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = gc.open(\"workflow_progress_tracker\").worksheet(\"Workflow Progress Tracker_2021_10_28-10_45_54_AM\")\n",
    "\n",
    "#existing = gd.get_as_dataframe(ws)\n",
    "existing = pd.DataFrame(ws.get_all_records())\n",
    "\n",
    "existing.set_index('', inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "existing = existing.rename_axis(None)\n",
    "existing.loc['pk'][:] = existing.loc['pk'][:].apply(lambda x: x.replace('\" \"', '\",\"'))\n",
    "existing.loc['pk'][1]\n",
    "\n",
    "updated = existing.append(df)\n",
    "gd.set_with_dataframe(ws, updated,include_index=True,include_column_header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spreadsheet_key = '1O1cMmYGxoIqP6xbzj6FG5owiKQVg57wx2O_XIA_hN_A'\n",
    "#spreadsheet_key = '1sPpBIkxrHbQNiTm5oPs9-5KrjsyXcgaVAxknJj-u8pY'\n",
    "#wks_name = 'Workflow Progress Tracker_' + date\n",
    "#d2g.upload(df, spreadsheet_key, \"TESTING ONLY\", credentials=credentials, row_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc = gspread.service_account(filename='/Users/priyash/Documents/GitHub/minihackathons/Notebooks/araxworkflowprogresstesting-2632632db8be.json')\n",
    "wksh = gc.open(\"workflow_progress_tracker\")\n",
    "#sh = wksh.worksheet(wks_name)\n",
    "sh = wksh.worksheet(\"Workflow Progress Tracker_2021_10_28-10_45_54_AM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule = ConditionalFormatRule(\n",
    "    ranges=[GridRange.from_a1_range('C2:{}23', sh)],\n",
    "    booleanRule=BooleanRule(\n",
    "        condition=BooleanCondition('TEXT_CONTAINS', ['Error: 501']),\n",
    "        format=CellFormat(textFormat=textFormat(bold=True), backgroundColor=Color(0.0, 0.75, 0.75))\n",
    "    )\n",
    ")\n",
    "rules = get_conditional_format_rules(sh)\n",
    "rules.append(rule)\n",
    "rules.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule = ConditionalFormatRule(\n",
    "    ranges=[GridRange.from_a1_range('C2:{}23', sh)],\n",
    "    booleanRule=BooleanRule(\n",
    "        condition=BooleanCondition('TEXT_CONTAINS', ['running']),\n",
    "        format=CellFormat(textFormat=textFormat(bold=True), backgroundColor=Color(0.0, 0.75, 0.75))\n",
    "    )\n",
    ")\n",
    "rules = get_conditional_format_rules(sh)\n",
    "rules.append(rule)\n",
    "rules.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule = ConditionalFormatRule(\n",
    "    ranges=[GridRange.from_a1_range('C2:{}23', sh)],\n",
    "    booleanRule=BooleanRule(\n",
    "        condition=BooleanCondition('TEXT_STARTS_WITH', ['Error']),\n",
    "        format=CellFormat(textFormat=textFormat(bold=True), backgroundColor=Color(1,0,0))\n",
    "    )\n",
    ")\n",
    "rules = get_conditional_format_rules(sh)\n",
    "rules.append(rule)\n",
    "rules.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule = ConditionalFormatRule(\n",
    "    ranges=[GridRange.from_a1_range('C2:{}23', sh)],\n",
    "    booleanRule=BooleanRule(\n",
    "        condition=BooleanCondition('TEXT_STARTS_WITH', ['Results']),\n",
    "        format=CellFormat(textFormat=textFormat(bold=True), backgroundColor=Color(0.0, 0.5, 0.0))\n",
    "    )\n",
    ")\n",
    "rules = get_conditional_format_rules(sh)\n",
    "rules.append(rule)\n",
    "rules.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule = ConditionalFormatRule(\n",
    "    ranges=[GridRange.from_a1_range('C2:{}23', sh)],\n",
    "    booleanRule=BooleanRule(\n",
    "        condition=BooleanCondition('TEXT_STARTS_WITH', ['No Results']),\n",
    "        format=CellFormat(textFormat=textFormat(bold=True), backgroundColor=Color(0.75, 0.75, 0))\n",
    "    )\n",
    ")\n",
    "rules = get_conditional_format_rules(sh)\n",
    "rules.append(rule)\n",
    "rules.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule = ConditionalFormatRule(\n",
    "    ranges=[GridRange.from_a1_range('C2:{}23', sh)],\n",
    "    booleanRule=BooleanRule(\n",
    "        condition=BooleanCondition('TEXT_STARTS_WITH', ['Unknown']),\n",
    "        format=CellFormat(textFormat=textFormat(bold=True), backgroundColor=Color(0.75, 0, 0.75))\n",
    "    )\n",
    ")\n",
    "rules = get_conditional_format_rules(sh)\n",
    "rules.append(rule)\n",
    "rules.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a range\n",
    "cell_list = sh.range('B20:AS20')\n",
    "\n",
    "# Update in batch\n",
    "sh.update_cells(cell_list,value_input_option='USER_ENTERED')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a range\n",
    "cell_list = sh.range('B23:AS23')\n",
    "\n",
    "# Update in batch\n",
    "sh.update_cells(cell_list,value_input_option='USER_ENTERED')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_frozen(sh, cols=1, rows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Push Dataframe 2\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws2 = gc.open(\"workflow_progress_tracker\").worksheet(\"edge_attribute_source_2021_10_28-10_45_54_AM\")\n",
    "\n",
    "#existing = gd.get_as_dataframe(ws)\n",
    "existing = pd.DataFrame(ws2.get_all_records())\n",
    "\n",
    "existing.set_index('', inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "existing = existing.rename_axis(None)\n",
    "\n",
    "updated = existing.append(df2test)\n",
    "gd.set_with_dataframe(ws2, updated,include_index=True,include_column_header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_frozen(ws2, cols=1, rows =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
